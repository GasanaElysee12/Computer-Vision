{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLO Version3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOwN5TK2TMRjvHmb5p8lnqB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GasanaElysee12/Computer-Vision/blob/main/YOLO_Version3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import the package\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os"
      ],
      "metadata": {
        "id": "V3Wt3QcBJCBT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF1pAXqcHyQO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# construct the argument parse and parse the arguments\n",
        "\n",
        "ap=argparse.ArgumentParser()\n",
        "ap.add_argument('-i', '--image', required=True, help='path to input image')\n",
        "ap.add_argument('-c', '--confidence', type=float, default=0.5, help='Threshold IoU')\n",
        "ap.add_argument('-m', '--threshold', type=float, default=0.3, help='threshold for Non Max Suppressiom')\n",
        "args= vars(ap.parse_args())\n",
        "\n",
        "# Loading coco class labels that have been used to train Yolo.\n",
        "\n",
        "labelsPath='coconame.names'\n",
        "Labels=open(labelsPath).read().strip().split('\\n')\n",
        "\n",
        "# Initialize the colors for each class\n",
        "Color=np.random.randint(0, 255, size=(len(Labels), 3), dtype='uint8')\n",
        "\n",
        "# Loading of weight and model configuration\n",
        "\n",
        "weightpath='/content/yolov3.weights'\n",
        "modelconfig='/content/yolov3_hyperparameters.cfg'\n",
        "\n",
        "# Load the YOLO network that has been on the dataset of 80 classes\n",
        "\n",
        "network=cv2.dnn.readNetFromDarknet(modelconfig, weightpath)\n",
        "\n",
        "#Loading the input images\n",
        "\n",
        "image=cv2.imread(args['image'])\n",
        "(H, W)=image.shape[:2]\n",
        "\n",
        "# Determining the only output layer name that we need from yolo\n",
        "\n",
        "layer=network.getLayerNames()\n",
        "liste=network.getUnconnectedLayersNames()\n",
        "\n",
        "# print(liste[:3])\n",
        "layer = [layer[i - 1] for i in liste]\n",
        "\n",
        "# Build blob from the input image and then perform a forward pass\n",
        "# of the yolo object detector, giving us our bounding boxes and associated to probability\n",
        "\n",
        "blob=cv2.dnn.blobFromImage(image,1/255.0, (416, 416), swapRB=True, crop=False)\n",
        "network.setInput(blob)\n",
        "layerOutputs=network.forward(layer)\n",
        "\n",
        "# Initialize the list of the detected bounding boxes, confidences, and class ids,respectively\n",
        "\n",
        "boxes=[]\n",
        "confidence=[]\n",
        "Class_ids=[]\n",
        "#Loop each layer output\n",
        "for output in layerOutputs:\n",
        "\n",
        "    #loop over each of the detections\n",
        "    for detection in output:\n",
        "        #Extract the bounding boxes, class ids and the confidence of the current detection\n",
        "        scores=detection[5:]\n",
        "        class_ids=np.argmax(scores)\n",
        "        prob=scores[class_ids]\n",
        "\n",
        "        # Now is time to remove weak detected object based on threshold probability\n",
        "        if prob > args['confidence']:\n",
        "\n",
        "            # Scale the bounding box coordinates back relative to the size of the image\n",
        "            # since YOLO actually return the center (x,y)-coordinates of the bounding boxes\n",
        "            #box height and width\n",
        "            box=detection[0:4]*np.array([W,H,W,H])\n",
        "            (center_x,center_y,width,height)=box.astype('int')\n",
        "\n",
        "            # To get the corner, we need to use center-h/2 and w/2\n",
        "            x=int(center_x-(width/2))\n",
        "            y=int(center_y-(height/2))\n",
        "\n",
        "            # Update or store the bounding box, class, and confidence.\n",
        "            boxes.append([x,y, int(width), int(height)])\n",
        "            # print(boxes[0][0])\n",
        "            confidence.append(float(prob))\n",
        "            Class_ids.append(class_ids)\n",
        "    # Apply non-max suppression\n",
        "    idxs=cv2.dnn.NMSBoxes(boxes, confidence, args['confidence'], args['threshold'])\n",
        "\n",
        "    # Ensuring that one box remained\n",
        "\n",
        "    if len(idxs)>0:\n",
        "        #Loop over the indexes we are keeping\n",
        "        for i in idxs.flatten():\n",
        "\n",
        "        #Extract bounding box coordinates:\n",
        "            b1=boxes[i][0]\n",
        "            b2=boxes[i][1]\n",
        "            b3 = boxes[i][2]\n",
        "            b4 = boxes[i][3]\n",
        "\n",
        "            (x,y)=(b1,b2)\n",
        "            (w,h)=(b3,b4)\n",
        "\n",
        "            #draw bounding box around rectangle and label on the image\n",
        "            color=[int(c) for c in Color[Class_ids[i]]]\n",
        "            # print(len(color))\n",
        "            cv2.rectangle(image, (x, y), (x+w, y+w), color, 2)\n",
        "\n",
        "\n",
        "            txt='{}:{:.4f}'.format(Labels[Class_ids[i]],confidence[i])\n",
        "            cv2.putText(image, txt,(x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "    # Show the output image\n",
        "    cv2.imshow('image',image)\n",
        "    cv2.waitKey(0)"
      ]
    }
  ]
}